{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import seed\n",
    "\n",
    "\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.layers.core import Dense \n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.models import model_from_json\n",
    "\n",
    "                                                                    #Data Preprocessing  \n",
    "data_dir = r'D:\\brazildata\\normal'\n",
    "merged_data = pd.DataFrame()\n",
    "counter = 1\n",
    "for filename in os.listdir(data_dir):#each for loop reads millions of data points from each fault catagory\n",
    "    #print(filename)\n",
    "    dataset=pd.read_csv(os.path.join(data_dir, filename), sep=',')\n",
    "    #print(dataset)\n",
    "\n",
    "    # tmp_dataset_squared = np.square(dataset)\n",
    "    # tmp_dataset_mean = np.array(tmp_dataset_squared.mean())\n",
    "    # dataset_mean_abs = np.sqrt(tmp_dataset_mean)\n",
    "\n",
    "    dataset_mean_abs = np.array(dataset.abs().mean())\n",
    "    dataset_mean_abs = pd.DataFrame(dataset_mean_abs.reshape(1,8))\n",
    "    #dataset_mean_abs.index = [filename]\n",
    "    filename = filename[:-4]\n",
    "    dataset_mean_abs['FaultType'] = 0                        #Add manual Label based on data folder\n",
    "    counter = counter+1\n",
    "    \n",
    "    merged_data = merged_data.append(dataset_mean_abs)\n",
    "\n",
    "data_dir = r'D:\\brazildata\\imbalance\\6g'\n",
    "#merged_data = pd.DataFrame()\n",
    "#print(counter)\n",
    "for filename in os.listdir(data_dir):\n",
    "    #print(filename)\n",
    "    dataset=pd.read_csv(os.path.join(data_dir, filename), sep=',')\n",
    "    #print(dataset)\n",
    "\n",
    "    # tmp_dataset_squared = np.square(dataset)\n",
    "    # tmp_dataset_mean = np.array(tmp_dataset_squared.mean())\n",
    "    # dataset_mean_abs = np.sqrt(tmp_dataset_mean)\n",
    "\n",
    "    dataset_mean_abs = np.array(dataset.abs().mean())\n",
    "    dataset_mean_abs = pd.DataFrame(dataset_mean_abs.reshape(1,8))\n",
    "    #dataset_mean_abs.index = [filename]\n",
    "    filename = filename[:-4]\n",
    "    dataset_mean_abs['FaultType'] = 1\n",
    "    counter = counter+1\n",
    "    merged_data = merged_data.append(dataset_mean_abs)\n",
    "\n",
    "data_dir = r'D:\\brazildata\\overhang\\ball_fault\\0g'\n",
    "#merged_data = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    #print(filename)\n",
    "    dataset=pd.read_csv(os.path.join(data_dir, filename), sep=',')\n",
    "    #print(dataset)\n",
    "\n",
    "    # tmp_dataset_squared = np.square(dataset)\n",
    "    # tmp_dataset_mean = np.array(tmp_dataset_squared.mean())\n",
    "    # dataset_mean_abs = np.sqrt(tmp_dataset_mean)\n",
    "\n",
    "    dataset_mean_abs = np.array(dataset.abs().mean())\n",
    "    dataset_mean_abs = pd.DataFrame(dataset_mean_abs.reshape(1,8))\n",
    "    #dataset_mean_abs.index = [filename]\n",
    "    filename = filename[:-4]\n",
    "    dataset_mean_abs['FaultType'] = 2\n",
    "    counter = counter+1\n",
    "    merged_data = merged_data.append(dataset_mean_abs)\n",
    "\n",
    "#print(counter)\n",
    "num_cols = ['Bearing 1']\n",
    "merged_data.columns = ['Bearing 1-1','Bearing 1-2','Bearing 2-1','Bearing 2-2', 'Bearing 3-1','Bearing 3-2','Bearing 4-1','Bearing 4-2', 'FaultType']\n",
    "merged_data.reset_index(drop=True, inplace=True)\n",
    "#merged_data.index = pd.to_datetime(merged_data.index, format='%Y.%m.%d.%H.%M.%S')\n",
    "#merged_data.index = pd.to_datetime(merged_data.index, format='UTC')\n",
    "#merged_data = merged_data.sort_index()\n",
    "merged_data.to_csv('Imb1.csv')\n",
    "#merged_data.index.names = ['index']\n",
    "#merged_data.head()\n",
    "num_cols = ['Bearing 1-1','Bearing 1-2','Bearing 2-1','Bearing 2-2', 'Bearing 3-1','Bearing 3-2','Bearing 4-1','Bearing 4-2']\n",
    "\n",
    "dataset_train = merged_data #['2004-02-12 11:02:39':'2004-02-13 23:52:39']\n",
    "#dataset_test = merged_data['2004-02-13 23:52:39':]\n",
    "#dataset_train.plot(merged_data.loc[:,\"date\"], merged_data.loc[:,\"Bearing 1\"], figsize = (12,6))\n",
    "#plt.plot(merged_data[\"FaultType\"], merged_data[num_cols])\n",
    "#plt.xticks(rotation=70)\n",
    "#Importing the necessary packages and libaries\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dataset = merged_data.values\n",
    "scaler = StandardScaler()\n",
    "X = dataset[:,0:8].astype(float)\n",
    "X = scaler.fit_transform(X)\n",
    "Y = dataset[:,8].astype(int)\n",
    "# print(type(Y[0]))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.8)\n",
    "\n",
    "neighbors = np.arange(1, 10)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    " \n",
    "# Loop over K values\n",
    "for i, k in enumerate(neighbors):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred=knn.predict(X_test)\n",
    "    # Compute training and test data accuracy\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "    cm_knn = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion matrix & classification report for K=', k)\n",
    "    print(cm_knn)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "# Generate plot\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy')\n",
    " \n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
